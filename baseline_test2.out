2020-04-26 16:23:33.289451: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-26 16:23:33.289651: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-26 16:23:33.289674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
04/26/2020 16:23:36 - WARNING - __main__ -   Device: cuda, n_gpu: 8
04/26/2020 16:23:36 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /cortex/users/jif24/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
04/26/2020 16:23:36 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "do_sample": false,
  "early_stopping": true,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522,
  "xla_device": null
}

04/26/2020 16:23:36 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /cortex/users/jif24/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
04/26/2020 16:23:36 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522,
  "xla_device": null
}

04/26/2020 16:23:36 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /cortex/users/jif24/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
04/26/2020 16:23:36 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /cortex/users/jif24/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
04/26/2020 16:23:39 - INFO - transformers.modeling_utils -   Weights of BertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']
04/26/2020 16:23:39 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
04/26/2020 16:23:44 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, doc_stride=128, eval_all_checkpoints=False, eval_checkpoints=False, evaluate_during_training=False, gradient_accumulation_steps=1, lang_id=0, learning_rate=3e-05, logging_steps=100, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_best_size=20, n_gpu=8, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=4.0, output_dir='./bert_baseline_test2/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=2, per_gpu_train_batch_size=2, predict_file='/ml/jif24/squad/dev-v2.0.json', save_steps=5000, seed=42, server_ip='', server_port='', tokenizer_name='', train_file='/ml/jif24/squad/train-v2.0.json', verbose_logging=False, version_2_with_negative=True, warmup_steps=0, weight_decay=0.0)
04/26/2020 16:23:44 - INFO - __main__ -   Loading features from cached file ./cached_train_bert-base-uncased_384
04/26/2020 16:24:13 - INFO - __main__ -   ***** Running training *****
04/26/2020 16:24:13 - INFO - __main__ -     Num examples = 131572
04/26/2020 16:24:13 - INFO - __main__ -     Num Epochs = 4
04/26/2020 16:24:13 - INFO - __main__ -     Instantaneous batch size per GPU = 2
04/26/2020 16:24:13 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16
04/26/2020 16:24:13 - INFO - __main__ -     Gradient Accumulation steps = 1
04/26/2020 16:24:13 - INFO - __main__ -     Total optimization steps = 32896
Epoch:   0%|          | 0/4 [00:00<?, ?it/s]
Iteration:   0%|          | 0/8224 [00:00<?, ?it/s][A04/26/2020 16:24:14 - INFO - __main__ -   [BRAINQA] Loss: 6.041034698486328

Iteration:   0%|          | 1/8224 [00:00<1:49:46,  1.25it/s][A04/26/2020 16:24:15 - INFO - __main__ -   [BRAINQA] Loss: 5.65833854675293

Iteration:   0%|          | 2/8224 [00:01<1:46:11,  1.29it/s][A04/26/2020 16:24:16 - INFO - __main__ -   [BRAINQA] Loss: 5.326959609985352

Iteration:   0%|          | 3/8224 [00:02<1:52:44,  1.22it/s][A04/26/2020 16:24:16 - INFO - __main__ -   [BRAINQA] Loss: 5.3212571144104

Iteration:   0%|          | 4/8224 [00:03<1:51:17,  1.23it/s][A04/26/2020 16:24:17 - INFO - __main__ -   [BRAINQA] Loss: 4.971601486206055

Iteration:   0%|          | 5/8224 [00:03<1:41:24,  1.35it/s][A04/26/2020 16:24:18 - INFO - __main__ -   [BRAINQA] Loss: 4.764031410217285

Iteration:   0%|          | 6/8224 [00:04<1:31:55,  1.49it/s][A04/26/2020 16:24:18 - INFO - __main__ -   [BRAINQA] Loss: 4.935406684875488

Iteration:   0%|          | 7/8224 [00:05<1:32:32,  1.48it/s][A04/26/2020 16:24:19 - INFO - __main__ -   [BRAINQA] Loss: 4.567686557769775

Iteration:   0%|          | 8/8224 [00:05<1:33:38,  1.46it/s][A04/26/2020 16:24:20 - INFO - __main__ -   [BRAINQA] Loss: 4.368325710296631

Iteration:   0%|          | 9/8224 [00:06<1:32:45,  1.48it/s][A04/26/2020 16:24:20 - INFO - __main__ -   [BRAINQA] Loss: 4.0003252029418945

Iteration:   0%|          | 10/8224 [00:07<1:32:42,  1.48it/s][A04/26/2020 16:24:21 - INFO - __main__ -   [BRAINQA] Loss: 4.068451881408691

Iteration:   0%|          | 11/8224 [00:07<1:32:31,  1.48it/s][A04/26/2020 16:24:22 - INFO - __main__ -   [BRAINQA] Loss: 4.39116096496582

Iteration:   0%|          | 12/8224 [00:08<1:38:18,  1.39it/s][A04/26/2020 16:24:22 - INFO - __main__ -   [BRAINQA] Loss: 4.3437910079956055

Iteration:   0%|          | 13/8224 [00:09<1:39:03,  1.38it/s][A04/26/2020 16:24:23 - INFO - __main__ -   [BRAINQA] Loss: 4.026484489440918

Iteration:   0%|          | 14/8224 [00:10<1:39:41,  1.37it/s][A04/26/2020 16:24:24 - INFO - __main__ -   [BRAINQA] Loss: 4.214083671569824

Iteration:   0%|          | 15/8224 [00:10<1:43:57,  1.32it/s][A04/26/2020 16:24:25 - INFO - __main__ -   [BRAINQA] Loss: 3.49273419380188

Iteration:   0%|          | 16/8224 [00:11<1:47:11,  1.28it/s][A04/26/2020 16:24:25 - INFO - __main__ -   [BRAINQA] Loss: 3.3066563606262207

Iteration:   0%|          | 17/8224 [00:12<1:39:40,  1.37it/s][A04/26/2020 16:24:26 - INFO - __main__ -   [BRAINQA] Loss: 4.638397216796875

Iteration:   0%|          | 18/8224 [00:12<1:31:18,  1.50it/s][A04/26/2020 16:24:27 - INFO - __main__ -   [BRAINQA] Loss: 3.455275535583496

Iteration:   0%|          | 19/8224 [00:13<1:34:43,  1.44it/s][A04/26/2020 16:24:27 - INFO - __main__ -   [BRAINQA] Loss: 3.527364492416382

Iteration:   0%|          | 20/8224 [00:14<1:33:40,  1.46it/s][A04/26/2020 16:24:28 - INFO - __main__ -   [BRAINQA] Loss: 3.8424363136291504

Iteration:   0%|          | 21/8224 [00:14<1:33:04,  1.47it/s][A04/26/2020 16:24:29 - INFO - __main__ -   [BRAINQA] Loss: 3.3921353816986084

Iteration:   0%|          | 22/8224 [00:15<1:33:03,  1.47it/s][A04/26/2020 16:24:29 - INFO - __main__ -   [BRAINQA] Loss: 3.321425199508667

Iteration:   0%|          | 23/8224 [00:16<1:33:22,  1.46it/s][A04/26/2020 16:24:30 - INFO - __main__ -   [BRAINQA] Loss: 3.609673023223877

Iteration:   0%|          | 24/8224 [00:17<1:38:47,  1.38it/s][A04/26/2020 16:24:31 - INFO - __main__ -   [BRAINQA] Loss: 3.786764144897461

Iteration:   0%|          | 25/8224 [00:17<1:42:57,  1.33it/s][A04/26/2020 16:24:32 - INFO - __main__ -   [BRAINQA] Loss: 3.4721121788024902

Iteration:   0%|          | 26/8224 [00:18<1:46:57,  1.28it/s][A04/26/2020 16:24:33 - INFO - __main__ -   [BRAINQA] Loss: 3.6055705547332764

Iteration:   0%|          | 27/8224 [00:19<1:47:22,  1.27it/s][A04/26/2020 16:24:33 - INFO - __main__ -   [BRAINQA] Loss: 3.920823574066162

Iteration:   0%|          | 28/8224 [00:20<1:43:34,  1.32it/s][A04/26/2020 16:24:34 - INFO - __main__ -   [BRAINQA] Loss: 3.133038282394409

Iteration:   0%|          | 29/8224 [00:20<1:35:06,  1.44it/s][A04/26/2020 16:24:35 - INFO - __main__ -   [BRAINQA] Loss: 3.89772891998291

Iteration:   0%|          | 30/8224 [00:21<1:30:49,  1.50it/s][A04/26/2020 16:24:35 - INFO - __main__ -   [BRAINQA] Loss: 3.306643486022949

Iteration:   0%|          | 31/8224 [00:22<1:34:49,  1.44it/s][A04/26/2020 16:24:36 - INFO - __main__ -   [BRAINQA] Loss: 3.2518229484558105

Iteration:   0%|          | 32/8224 [00:22<1:35:50,  1.42it/s][A04/26/2020 16:24:37 - INFO - __main__ -   [BRAINQA] Loss: 3.5471439361572266

Iteration:   0%|          | 33/8224 [00:23<1:35:06,  1.44it/s][A04/26/2020 16:24:37 - INFO - __main__ -   [BRAINQA] Loss: 3.3950235843658447

Iteration:   0%|          | 34/8224 [00:24<1:34:48,  1.44it/s][A04/26/2020 16:24:38 - INFO - __main__ -   [BRAINQA] Loss: 3.7587344646453857

Iteration:   0%|          | 35/8224 [00:24<1:34:45,  1.44it/s][A04/26/2020 16:24:39 - INFO - __main__ -   [BRAINQA] Loss: 3.5294790267944336

Iteration:   0%|          | 36/8224 [00:25<1:36:45,  1.41it/s][A04/26/2020 16:24:40 - INFO - __main__ -   [BRAINQA] Loss: 4.146527290344238

Iteration:   0%|          | 37/8224 [00:26<1:41:24,  1.35it/s][A04/26/2020 16:24:40 - INFO - __main__ -   [BRAINQA] Loss: 3.4852817058563232

Iteration:   0%|          | 38/8224 [00:27<1:42:22,  1.33it/s][A04/26/2020 16:24:41 - INFO - __main__ -   [BRAINQA] Loss: 3.8534328937530518

Iteration:   0%|          | 39/8224 [00:28<1:44:58,  1.30it/s][A04/26/2020 16:24:42 - INFO - __main__ -   [BRAINQA] Loss: 3.833845615386963

Iteration:   0%|          | 40/8224 [00:28<1:39:43,  1.37it/s][A04/26/2020 16:24:43 - INFO - __main__ -   [BRAINQA] Loss: 2.995821952819824

Iteration:   0%|          | 41/8224 [00:29<1:34:30,  1.44it/s][A04/26/2020 16:24:43 - INFO - __main__ -   [BRAINQA] Loss: 3.4157142639160156

Iteration:   1%|          | 42/8224 [00:29<1:29:58,  1.52it/s][A04/26/2020 16:24:44 - INFO - __main__ -   [BRAINQA] Loss: 3.2616591453552246

Iteration:   1%|          | 43/8224 [00:30<1:34:22,  1.44it/s][A04/26/2020 16:24:45 - INFO - __main__ -   [BRAINQA] Loss: 2.9707891941070557

Iteration:   1%|          | 44/8224 [00:31<1:36:17,  1.42it/s][A04/26/2020 16:24:45 - INFO - __main__ -   [BRAINQA] Loss: 3.365255355834961

Iteration:   1%|          | 45/8224 [00:32<1:35:10,  1.43it/s][A04/26/2020 16:24:46 - INFO - __main__ -   [BRAINQA] Loss: 3.301464319229126

Iteration:   1%|          | 46/8224 [00:32<1:35:14,  1.43it/s][A04/26/2020 16:24:47 - INFO - __main__ -   [BRAINQA] Loss: 3.4034600257873535

Iteration:   1%|          | 47/8224 [00:33<1:35:07,  1.43it/s][A04/26/2020 16:24:47 - INFO - __main__ -   [BRAINQA] Loss: 3.308335542678833

Iteration:   1%|          | 48/8224 [00:34<1:36:11,  1.42it/s][A04/26/2020 16:24:48 - INFO - __main__ -   [BRAINQA] Loss: 3.7433362007141113

Iteration:   1%|          | 49/8224 [00:35<1:46:01,  1.29it/s][A04/26/2020 16:24:49 - INFO - __main__ -   [BRAINQA] Loss: 4.27522087097168

Iteration:   1%|          | 50/8224 [00:35<1:38:43,  1.38it/s][A04/26/2020 16:24:50 - INFO - __main__ -   [BRAINQA] Loss: 3.3553664684295654

Iteration:   1%|          | 51/8224 [00:36<1:41:54,  1.34it/s][A04/26/2020 16:24:50 - INFO - __main__ -   [BRAINQA] Loss: 3.910982131958008

Iteration:   1%|          | 52/8224 [00:37<1:38:06,  1.39it/s][A04/26/2020 16:24:51 - INFO - __main__ -   [BRAINQA] Loss: 3.19588565826416

Iteration:   1%|          | 53/8224 [00:37<1:34:55,  1.43it/s][A04/26/2020 16:24:52 - INFO - __main__ -   [BRAINQA] Loss: 2.8723583221435547

Iteration:   1%|          | 54/8224 [00:38<1:31:07,  1.49it/s][A04/26/2020 16:24:52 - INFO - __main__ -   [BRAINQA] Loss: 3.606135606765747

Iteration:   1%|          | 55/8224 [00:39<1:34:02,  1.45it/s][A04/26/2020 16:24:53 - INFO - __main__ -   [BRAINQA] Loss: 3.2112293243408203

Iteration:   1%|          | 56/8224 [00:39<1:37:22,  1.40it/s][A04/26/2020 16:24:54 - INFO - __main__ -   [BRAINQA] Loss: 3.479604721069336

Iteration:   1%|          | 57/8224 [00:40<1:36:40,  1.41it/s][A04/26/2020 16:24:55 - INFO - __main__ -   [BRAINQA] Loss: 2.428241729736328

Iteration:   1%|          | 58/8224 [00:41<1:36:28,  1.41it/s][A04/26/2020 16:24:55 - INFO - __main__ -   [BRAINQA] Loss: 2.6695146560668945

Iteration:   1%|          | 59/8224 [00:42<1:33:25,  1.46it/s][A04/26/2020 16:24:56 - INFO - __main__ -   [BRAINQA] Loss: 2.3604493141174316

Iteration:   1%|          | 60/8224 [00:42<1:41:52,  1.34it/s][A04/26/2020 16:24:57 - INFO - __main__ -   [BRAINQA] Loss: 2.796865463256836

Iteration:   1%|          | 61/8224 [00:43<1:43:09,  1.32it/s][A04/26/2020 16:24:57 - INFO - __main__ -   [BRAINQA] Loss: 3.221662759780884

Iteration:   1%|          | 62/8224 [00:44<1:37:21,  1.40it/s][A04/26/2020 16:24:58 - INFO - __main__ -   [BRAINQA] Loss: 3.0713324546813965

Iteration:   1%|          | 63/8224 [00:45<1:40:47,  1.35it/s][A04/26/2020 16:24:59 - INFO - __main__ -   [BRAINQA] Loss: 2.9667086601257324

Iteration:   1%|          | 64/8224 [00:45<1:36:26,  1.41it/s][A04/26/2020 16:25:00 - INFO - __main__ -   [BRAINQA] Loss: 3.157768726348877

Iteration:   1%|          | 65/8224 [00:46<1:35:45,  1.42it/s][A04/26/2020 16:25:00 - INFO - __main__ -   [BRAINQA] Loss: 3.1693778038024902

Iteration:   1%|          | 66/8224 [00:47<1:31:46,  1.48it/s][A04/26/2020 16:25:01 - INFO - __main__ -   [BRAINQA] Loss: 3.136671543121338

Iteration:   1%|          | 67/8224 [00:47<1:35:01,  1.43it/s][A04/26/2020 16:25:02 - INFO - __main__ -   [BRAINQA] Loss: 2.183180332183838

Iteration:   1%|          | 68/8224 [00:48<1:38:19,  1.38it/s][A04/26/2020 16:25:02 - INFO - __main__ -   [BRAINQA] Loss: 2.771320343017578

Iteration:   1%|          | 69/8224 [00:49<1:37:43,  1.39it/s][A04/26/2020 16:25:03 - INFO - __main__ -   [BRAINQA] Loss: 2.748202323913574

Iteration:   1%|          | 70/8224 [00:50<1:37:13,  1.40it/s][A04/26/2020 16:25:04 - INFO - __main__ -   [BRAINQA] Loss: 2.5778427124023438

Iteration:   1%|          | 71/8224 [00:50<1:32:21,  1.47it/s][A04/26/2020 16:25:05 - INFO - __main__ -   [BRAINQA] Loss: 2.646695375442505

Iteration:   1%|          | 72/8224 [00:51<1:43:38,  1.31it/s][A04/26/2020 16:25:05 - INFO - __main__ -   [BRAINQA] Loss: 3.341038703918457

Iteration:   1%|          | 73/8224 [00:52<1:40:11,  1.36it/s][A04/26/2020 16:25:06 - INFO - __main__ -   [BRAINQA] Loss: 2.6291260719299316

Iteration:   1%|          | 74/8224 [00:52<1:35:55,  1.42it/s][A04/26/2020 16:25:07 - INFO - __main__ -   [BRAINQA] Loss: 2.576028823852539

Iteration:   1%|          | 75/8224 [00:53<1:40:10,  1.36it/s][A04/26/2020 16:25:07 - INFO - __main__ -   [BRAINQA] Loss: 2.4503121376037598

Iteration:   1%|          | 76/8224 [00:54<1:37:26,  1.39it/s][A04/26/2020 16:25:08 - INFO - __main__ -   [BRAINQA] Loss: 3.0601282119750977

Iteration:   1%|          | 77/8224 [00:55<1:36:41,  1.40it/s][A04/26/2020 16:25:09 - INFO - __main__ -   [BRAINQA] Loss: 2.887819290161133

Iteration:   1%|          | 78/8224 [00:55<1:32:31,  1.47it/s][A04/26/2020 16:25:10 - INFO - __main__ -   [BRAINQA] Loss: 3.3815886974334717

Iteration:   1%|          | 79/8224 [00:56<1:36:10,  1.41it/s][A04/26/2020 16:25:10 - INFO - __main__ -   [BRAINQA] Loss: 3.541049003601074

Iteration:   1%|          | 80/8224 [00:57<1:38:42,  1.38it/s][A04/26/2020 16:25:11 - INFO - __main__ -   [BRAINQA] Loss: 3.6997122764587402

Iteration:   1%|          | 81/8224 [00:57<1:37:41,  1.39it/s][A04/26/2020 16:25:12 - INFO - __main__ -   [BRAINQA] Loss: 2.10935640335083

Iteration:   1%|          | 82/8224 [00:58<1:34:20,  1.44it/s][A04/26/2020 16:25:12 - INFO - __main__ -   [BRAINQA] Loss: 2.6389758586883545

Iteration:   1%|          | 83/8224 [00:59<1:34:46,  1.43it/s][A04/26/2020 16:25:13 - INFO - __main__ -   [BRAINQA] Loss: 3.333347797393799

Iteration:   1%|          | 84/8224 [01:00<1:41:21,  1.34it/s][A04/26/2020 16:25:14 - INFO - __main__ -   [BRAINQA] Loss: 3.202026844024658

Iteration:   1%|          | 85/8224 [01:00<1:39:08,  1.37it/s][A04/26/2020 16:25:15 - INFO - __main__ -   [BRAINQA] Loss: 2.948725700378418

Iteration:   1%|          | 86/8224 [01:01<1:33:28,  1.45it/s][A04/26/2020 16:25:15 - INFO - __main__ -   [BRAINQA] Loss: 3.026545524597168

Iteration:   1%|          | 87/8224 [01:02<1:37:33,  1.39it/s][A04/26/2020 16:25:16 - INFO - __main__ -   [BRAINQA] Loss: 2.372174024581909

Iteration:   1%|          | 88/8224 [01:02<1:36:42,  1.40it/s][A04/26/2020 16:25:17 - INFO - __main__ -   [BRAINQA] Loss: 2.808889389038086

Iteration:   1%|          | 89/8224 [01:03<1:35:49,  1.41it/s][A04/26/2020 16:25:17 - INFO - __main__ -   [BRAINQA] Loss: 2.5610570907592773

Iteration:   1%|          | 90/8224 [01:04<1:32:25,  1.47it/s][A04/26/2020 16:25:18 - INFO - __main__ -   [BRAINQA] Loss: 2.753119707107544

Iteration:   1%|          | 91/8224 [01:04<1:35:36,  1.42it/s][A04/26/2020 16:25:19 - INFO - __main__ -   [BRAINQA] Loss: 2.5734851360321045

Iteration:   1%|          | 92/8224 [01:05<1:38:38,  1.37it/s][A04/26/2020 16:25:20 - INFO - __main__ -   [BRAINQA] Loss: 3.1857056617736816

Iteration:   1%|          | 93/8224 [01:06<1:37:43,  1.39it/s][A04/26/2020 16:25:20 - INFO - __main__ -   [BRAINQA] Loss: 3.3646700382232666

Iteration:   1%|          | 94/8224 [01:07<1:34:06,  1.44it/s][A04/26/2020 16:25:21 - INFO - __main__ -   [BRAINQA] Loss: 3.0878469944000244

Iteration:   1%|          | 95/8224 [01:07<1:34:02,  1.44it/s][A04/26/2020 16:25:22 - INFO - __main__ -   [BRAINQA] Loss: 3.0065431594848633

Iteration:   1%|          | 96/8224 [01:08<1:40:31,  1.35it/s][A04/26/2020 16:25:22 - INFO - __main__ -   [BRAINQA] Loss: 3.081717014312744

Iteration:   1%|          | 97/8224 [01:09<1:38:22,  1.38it/s][A04/26/2020 16:25:23 - INFO - __main__ -   [BRAINQA] Loss: 2.871812343597412

Iteration:   1%|          | 98/8224 [01:09<1:33:30,  1.45it/s][A04/26/2020 16:25:24 - INFO - __main__ -   [BRAINQA] Loss: 2.0865418910980225
/cortex/users/jif24/brainqa/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
04/26/2020 16:25:24 - INFO - __main__ -   [BRAINQA] Eval loss: 3.397

Iteration:   1%|          | 99/8224 [01:10<1:37:19,  1.39it/s][A04/26/2020 16:25:25 - INFO - __main__ -   [BRAINQA] Loss: 1.9330999851226807

Iteration:   1%|          | 100/8224 [01:11<1:37:06,  1.39it/s][A04/26/2020 16:25:25 - INFO - __main__ -   [BRAINQA] Loss: 2.1284050941467285

Iteration:   1%|          | 101/8224 [01:12<1:36:14,  1.41it/s][A04/26/2020 16:25:26 - INFO - __main__ -   [BRAINQA] Loss: 2.6291632652282715

Iteration:   1%|          | 102/8224 [01:12<1:33:44,  1.44it/s][A04/26/2020 16:25:27 - INFO - __main__ -   [BRAINQA] Loss: 2.083789348602295

Iteration:   1%|▏         | 103/8224 [01:13<1:35:18,  1.42it/s][A04/26/2020 16:25:27 - INFO - __main__ -   [BRAINQA] Loss: 2.9575326442718506

Iteration:   1%|▏         | 104/8224 [01:14<1:39:23,  1.36it/s][A04/26/2020 16:25:28 - INFO - __main__ -   [BRAINQA] Loss: 3.3301467895507812

Iteration:   1%|▏         | 105/8224 [01:14<1:37:49,  1.38it/s][A04/26/2020 16:25:29 - INFO - __main__ -   [BRAINQA] Loss: 3.97330904006958

Iteration:   1%|▏         | 106/8224 [01:15<1:34:11,  1.44it/s][A04/26/2020 16:25:30 - INFO - __main__ -   [BRAINQA] Loss: 2.1492762565612793

Iteration:   1%|▏         | 107/8224 [01:16<1:35:36,  1.42it/s][A04/26/2020 16:25:30 - INFO - __main__ -   [BRAINQA] Loss: 2.4653778076171875

Iteration:   1%|▏         | 108/8224 [01:17<1:40:29,  1.35it/s][A04/26/2020 16:25:31 - INFO - __main__ -   [BRAINQA] Loss: 2.34373140335083

Iteration:   1%|▏         | 109/8224 [01:17<1:38:24,  1.37it/s][A04/26/2020 16:25:32 - INFO - __main__ -   [BRAINQA] Loss: 3.140117645263672

Iteration:   1%|▏         | 110/8224 [01:18<1:33:55,  1.44it/s][A04/26/2020 16:25:32 - INFO - __main__ -   [BRAINQA] Loss: 2.7210445404052734

Iteration:   1%|▏         | 111/8224 [01:19<1:37:28,  1.39it/s][A04/26/2020 16:25:33 - INFO - __main__ -   [BRAINQA] Loss: 2.589637279510498

Iteration:   1%|▏         | 112/8224 [01:20<1:37:47,  1.38it/s][A04/26/2020 16:25:34 - INFO - __main__ -   [BRAINQA] Loss: 2.462193489074707

Iteration:   1%|▏         | 113/8224 [01:20<1:36:36,  1.40it/s][A04/26/2020 16:25:35 - INFO - __main__ -   [BRAINQA] Loss: 2.2897613048553467

Iteration:   1%|▏         | 114/8224 [01:21<1:32:51,  1.46it/s][A04/26/2020 16:25:35 - INFO - __main__ -   [BRAINQA] Loss: 2.739251136779785

Iteration:   1%|▏         | 115/8224 [01:22<1:36:42,  1.40it/s][A04/26/2020 16:25:36 - INFO - __main__ -   [BRAINQA] Loss: 2.9649906158447266

Iteration:   1%|▏         | 116/8224 [01:22<1:38:55,  1.37it/s][A04/26/2020 16:25:37 - INFO - __main__ -   [BRAINQA] Loss: 2.929342746734619

Iteration:   1%|▏         | 117/8224 [01:23<1:37:36,  1.38it/s][A04/26/2020 16:25:37 - INFO - __main__ -   [BRAINQA] Loss: 3.4452831745147705

Iteration:   1%|▏         | 118/8224 [01:24<1:34:14,  1.43it/s][A04/26/2020 16:25:38 - INFO - __main__ -   [BRAINQA] Loss: 3.745575428009033

Iteration:   1%|▏         | 119/8224 [01:25<1:38:06,  1.38it/s][A04/26/2020 16:25:39 - INFO - __main__ -   [BRAINQA] Loss: 2.9404988288879395

Iteration:   1%|▏         | 120/8224 [01:25<1:39:23,  1.36it/s][A04/26/2020 16:25:40 - INFO - __main__ -   [BRAINQA] Loss: 2.193826198577881

Iteration:   1%|▏         | 121/8224 [01:26<1:37:43,  1.38it/s][A04/26/2020 16:25:40 - INFO - __main__ -   [BRAINQA] Loss: 2.978367805480957

Iteration:   1%|▏         | 122/8224 [01:27<1:32:25,  1.46it/s][A04/26/2020 16:25:41 - INFO - __main__ -   [BRAINQA] Loss: 2.144538402557373

Iteration:   1%|▏         | 123/8224 [01:27<1:37:15,  1.39it/s][A04/26/2020 16:25:42 - INFO - __main__ -   [BRAINQA] Loss: 2.5768306255340576

Iteration:   2%|▏         | 124/8224 [01:28<1:38:12,  1.37it/s][A04/26/2020 16:25:42 - INFO - __main__ -   [BRAINQA] Loss: 2.5162930488586426

Iteration:   2%|▏         | 125/8224 [01:29<1:36:46,  1.39it/s][A04/26/2020 16:25:43 - INFO - __main__ -   [BRAINQA] Loss: 2.0750484466552734

Iteration:   2%|▏         | 126/8224 [01:29<1:32:59,  1.45it/s][A04/26/2020 16:25:44 - INFO - __main__ -   [BRAINQA] Loss: 2.6915197372436523

Iteration:   2%|▏         | 127/8224 [01:30<1:37:08,  1.39it/s][A04/26/2020 16:25:45 - INFO - __main__ -   [BRAINQA] Loss: 2.78372859954834

Iteration:   2%|▏         | 128/8224 [01:31<1:38:26,  1.37it/s][A04/26/2020 16:25:45 - INFO - __main__ -   [BRAINQA] Loss: 2.394108295440674

Iteration:   2%|▏         | 129/8224 [01:32<1:37:05,  1.39it/s][A04/26/2020 16:25:46 - INFO - __main__ -   [BRAINQA] Loss: 2.187046527862549

Iteration:   2%|▏         | 130/8224 [01:32<1:32:33,  1.46it/s][A04/26/2020 16:25:47 - INFO - __main__ -   [BRAINQA] Loss: 2.802560806274414

Iteration:   2%|▏         | 131/8224 [01:33<1:37:36,  1.38it/s][A04/26/2020 16:25:47 - INFO - __main__ -   [BRAINQA] Loss: 2.9695587158203125

Iteration:   2%|▏         | 132/8224 [01:34<1:37:52,  1.38it/s][A04/26/2020 16:25:48 - INFO - __main__ -   [BRAINQA] Loss: 2.583895206451416

Iteration:   2%|▏         | 133/8224 [01:35<1:36:26,  1.40it/s][A04/26/2020 16:25:49 - INFO - __main__ -   [BRAINQA] Loss: 2.7767491340637207

Iteration:   2%|▏         | 134/8224 [01:35<1:32:23,  1.46it/s][A04/26/2020 16:25:50 - INFO - __main__ -   [BRAINQA] Loss: 2.3421292304992676

Iteration:   2%|▏         | 135/8224 [01:36<1:36:18,  1.40it/s][A04/26/2020 16:25:50 - INFO - __main__ -   [BRAINQA] Loss: 2.579533338546753

Iteration:   2%|▏         | 136/8224 [01:37<1:38:22,  1.37it/s][A04/26/2020 16:25:51 - INFO - __main__ -   [BRAINQA] Loss: 1.8949105739593506

Iteration:   2%|▏         | 137/8224 [01:37<1:37:18,  1.39it/s][A04/26/2020 16:25:52 - INFO - __main__ -   [BRAINQA] Loss: 2.938331127166748

Iteration:   2%|▏         | 138/8224 [01:38<1:32:54,  1.45it/s][A04/26/2020 16:25:52 - INFO - __main__ -   [BRAINQA] Loss: 3.3221945762634277

Iteration:   2%|▏         | 139/8224 [01:39<1:36:31,  1.40it/s][A04/26/2020 16:25:53 - INFO - __main__ -   [BRAINQA] Loss: 2.203948497772217

Iteration:   2%|▏         | 140/8224 [01:40<1:38:44,  1.36it/s][A04/26/2020 16:25:54 - INFO - __main__ -   [BRAINQA] Loss: 2.6814591884613037

Iteration:   2%|▏         | 141/8224 [01:40<1:37:15,  1.39it/s][A04/26/2020 16:25:55 - INFO - __main__ -   [BRAINQA] Loss: 2.8747525215148926

Iteration:   2%|▏         | 142/8224 [01:41<1:34:52,  1.42it/s][A04/26/2020 16:25:55 - INFO - __main__ -   [BRAINQA] Loss: 2.802978038787842

Iteration:   2%|▏         | 143/8224 [01:42<1:39:24,  1.35it/s][A04/26/2020 16:25:56 - INFO - __main__ -   [BRAINQA] Loss: 2.456411838531494

Iteration:   2%|▏         | 144/8224 [01:42<1:37:32,  1.38it/s][A04/26/2020 16:25:57 - INFO - __main__ -   [BRAINQA] Loss: 2.596257448196411

Iteration:   2%|▏         | 145/8224 [01:43<1:35:22,  1.41it/s][A04/26/2020 16:25:57 - INFO - __main__ -   [BRAINQA] Loss: 2.881904363632202

Iteration:   2%|▏         | 146/8224 [01:44<1:31:38,  1.47it/s][A04/26/2020 16:25:58 - INFO - __main__ -   [BRAINQA] Loss: 2.5675840377807617

Iteration:   2%|▏         | 147/8224 [01:45<1:39:45,  1.35it/s][A04/26/2020 16:25:59 - INFO - __main__ -   [BRAINQA] Loss: 2.3052096366882324

Iteration:   2%|▏         | 148/8224 [01:45<1:39:56,  1.35it/s][A04/26/2020 16:26:00 - INFO - __main__ -   [BRAINQA] Loss: 3.202974796295166

Iteration:   2%|▏         | 149/8224 [01:46<1:37:40,  1.38it/s][A04/26/2020 16:26:00 - INFO - __main__ -   [BRAINQA] Loss: 2.1783957481384277

Iteration:   2%|▏         | 150/8224 [01:47<1:32:08,  1.46it/s][A04/26/2020 16:26:01 - INFO - __main__ -   [BRAINQA] Loss: 3.227987766265869

Iteration:   2%|▏         | 151/8224 [01:47<1:36:46,  1.39it/s][A04/26/2020 16:26:02 - INFO - __main__ -   [BRAINQA] Loss: 2.5360970497131348

Iteration:   2%|▏         | 152/8224 [01:48<1:38:22,  1.37it/s][A04/26/2020 16:26:02 - INFO - __main__ -   [BRAINQA] Loss: 2.1591501235961914

Iteration:   2%|▏         | 153/8224 [01:49<1:35:09,  1.41it/s][A04/26/2020 16:26:03 - INFO - __main__ -   [BRAINQA] Loss: 3.1966137886047363

Iteration:   2%|▏         | 154/8224 [01:50<1:38:57,  1.36it/s][A04/26/2020 16:26:04 - INFO - __main__ -   [BRAINQA] Loss: 2.588604688644409

Iteration:   2%|▏         | 155/8224 [01:50<1:35:29,  1.41it/s][A04/26/2020 16:26:05 - INFO - __main__ -   [BRAINQA] Loss: 2.470264196395874

Iteration:   2%|▏         | 156/8224 [01:51<1:34:27,  1.42it/s][A04/26/2020 16:26:05 - INFO - __main__ -   [BRAINQA] Loss: 2.5734691619873047

Iteration:   2%|▏         | 157/8224 [01:52<1:34:12,  1.43it/s][A04/26/2020 16:26:06 - INFO - __main__ -   [BRAINQA] Loss: 2.805187702178955

Iteration:   2%|▏         | 158/8224 [01:52<1:29:32,  1.50it/s][A04/26/2020 16:26:07 - INFO - __main__ -   [BRAINQA] Loss: 2.240884304046631

Iteration:   2%|▏         | 159/8224 [01:53<1:41:46,  1.32it/s][A04/26/2020 16:26:08 - INFO - __main__ -   [BRAINQA] Loss: 2.4382309913635254

Iteration:   2%|▏         | 160/8224 [01:54<1:39:43,  1.35it/s][A04/26/2020 16:26:08 - INFO - __main__ -   [BRAINQA] Loss: 2.904379367828369

Iteration:   2%|▏         | 161/8224 [01:55<1:38:09,  1.37it/s][A04/26/2020 16:26:09 - INFO - __main__ -   [BRAINQA] Loss: 3.0550172328948975

Iteration:   2%|▏         | 162/8224 [01:55<1:33:11,  1.44it/s][A04/26/2020 16:26:10 - INFO - __main__ -   [BRAINQA] Loss: 2.6125547885894775

Iteration:   2%|▏         | 163/8224 [01:56<1:37:34,  1.38it/s][A04/26/2020 16:26:10 - INFO - __main__ -   [BRAINQA] Loss: 2.922091484069824

Iteration:   2%|▏         | 164/8224 [01:57<1:37:39,  1.38it/s][A04/26/2020 16:26:11 - INFO - __main__ -   [BRAINQA] Loss: 2.5969550609588623

Iteration:   2%|▏         | 165/8224 [01:57<1:35:20,  1.41it/s][A04/26/2020 16:26:12 - INFO - __main__ -   [BRAINQA] Loss: 2.4962456226348877

Iteration:   2%|▏         | 166/8224 [01:58<1:39:27,  1.35it/s][A04/26/2020 16:26:13 - INFO - __main__ -   [BRAINQA] Loss: 3.3649983406066895

Iteration:   2%|▏         | 167/8224 [01:59<1:32:55,  1.45it/s][A04/26/2020 16:26:13 - INFO - __main__ -   [BRAINQA] Loss: 2.4208972454071045

Iteration:   2%|▏         | 168/8224 [01:59<1:32:56,  1.44it/s][A04/26/2020 16:26:14 - INFO - __main__ -   [BRAINQA] Loss: 2.81829571723938

Iteration:   2%|▏         | 169/8224 [02:00<1:32:33,  1.45it/s][A04/26/2020 16:26:14 - INFO - __main__ -   [BRAINQA] Loss: 2.137838125228882

Iteration:   2%|▏         | 170/8224 [02:01<1:30:56,  1.48it/s][A04/26/2020 16:26:15 - INFO - __main__ -   [BRAINQA] Loss: 2.3138909339904785

Iteration:   2%|▏         | 171/8224 [02:02<1:43:00,  1.30it/s][A04/26/2020 16:26:16 - INFO - __main__ -   [BRAINQA] Loss: 2.3195860385894775

Iteration:   2%|▏         | 172/8224 [02:03<1:40:33,  1.33it/s][A04/26/2020 16:26:17 - INFO - __main__ -   [BRAINQA] Loss: 2.0460920333862305

Iteration:   2%|▏         | 173/8224 [02:03<1:38:09,  1.37it/s][A04/26/2020 16:26:18 - INFO - __main__ -   [BRAINQA] Loss: 2.459376096725464

Iteration:   2%|▏         | 174/8224 [02:04<1:33:45,  1.43it/s][A04/26/2020 16:26:18 - INFO - __main__ -   [BRAINQA] Loss: 1.9774084091186523

Iteration:   2%|▏         | 175/8224 [02:05<1:43:22,  1.30it/s][A04/26/2020 16:26:19 - INFO - __main__ -   [BRAINQA] Loss: 2.2529706954956055

Iteration:   2%|▏         | 176/8224 [02:05<1:37:16,  1.38it/s][A04/26/2020 16:26:20 - INFO - __main__ -   [BRAINQA] Loss: 1.7106943130493164

Iteration:   2%|▏         | 177/8224 [02:06<1:36:07,  1.40it/s][A04/26/2020 16:26:20 - INFO - __main__ -   [BRAINQA] Loss: 2.1953344345092773

Iteration:   2%|▏         | 178/8224 [02:07<1:29:49,  1.49it/s][A04/26/2020 16:26:21 - INFO - __main__ -   [BRAINQA] Loss: 2.5595359802246094

Iteration:   2%|▏         | 179/8224 [02:07<1:21:41,  1.64it/s][A04/26/2020 16:26:21 - INFO - __main__ -   [BRAINQA] Loss: 3.093217372894287

Iteration:   2%|▏         | 180/8224 [02:08<1:18:27,  1.71it/s][A04/26/2020 16:26:22 - INFO - __main__ -   [BRAINQA] Loss: 2.4332261085510254

Iteration:   2%|▏         | 181/8224 [02:08<1:16:59,  1.74it/s][A04/26/2020 16:26:22 - INFO - __main__ -   [BRAINQA] Loss: 2.462843894958496

Iteration:   2%|▏         | 182/8224 [02:09<1:15:36,  1.77it/s][A04/26/2020 16:26:23 - INFO - __main__ -   [BRAINQA] Loss: 2.4212167263031006

Iteration:   2%|▏         | 183/8224 [02:09<1:18:22,  1.71it/s][A04/26/2020 16:26:24 - INFO - __main__ -   [BRAINQA] Loss: 2.9356985092163086

Iteration:   2%|▏         | 184/8224 [02:10<1:21:47,  1.64it/s][A04/26/2020 16:26:24 - INFO - __main__ -   [BRAINQA] Loss: 2.1406469345092773

Iteration:   2%|▏         | 185/8224 [02:11<1:24:00,  1.59it/s][A04/26/2020 16:26:25 - INFO - __main__ -   [BRAINQA] Loss: 2.159609794616699

Iteration:   2%|▏         | 186/8224 [02:11<1:24:21,  1.59it/s][A04/26/2020 16:26:26 - INFO - __main__ -   [BRAINQA] Loss: 2.132148027420044

Iteration:   2%|▏         | 187/8224 [02:12<1:23:26,  1.61it/s][A04/26/2020 16:26:26 - INFO - __main__ -   [BRAINQA] Loss: 2.121347427368164

Iteration:   2%|▏         | 188/8224 [02:13<1:29:42,  1.49it/s][A04/26/2020 16:26:27 - INFO - __main__ -   [BRAINQA] Loss: 2.501946449279785

Iteration:   2%|▏         | 189/8224 [02:13<1:26:33,  1.55it/s][A04/26/2020 16:26:28 - INFO - __main__ -   [BRAINQA] Loss: 2.856851100921631

Iteration:   2%|▏         | 190/8224 [02:14<1:26:01,  1.56it/s][A04/26/2020 16:26:28 - INFO - __main__ -   [BRAINQA] Loss: 2.9235568046569824

Iteration:   2%|▏         | 191/8224 [02:15<1:24:00,  1.59it/s][A04/26/2020 16:26:29 - INFO - __main__ -   [BRAINQA] Loss: 2.02667236328125

Iteration:   2%|▏         | 192/8224 [02:15<1:17:48,  1.72it/s][A04/26/2020 16:26:29 - INFO - __main__ -   [BRAINQA] Loss: 2.3415396213531494

Iteration:   2%|▏         | 193/8224 [02:16<1:15:46,  1.77it/s][A04/26/2020 16:26:30 - INFO - __main__ -   [BRAINQA] Loss: 2.6276001930236816

Iteration:   2%|▏         | 194/8224 [02:16<1:14:53,  1.79it/s][A04/26/2020 16:26:30 - INFO - __main__ -   [BRAINQA] Loss: 3.224560260772705

Iteration:   2%|▏         | 195/8224 [02:17<1:14:01,  1.81it/s][A04/26/2020 16:26:31 - INFO - __main__ -   [BRAINQA] Loss: 2.0275111198425293

Iteration:   2%|▏         | 196/8224 [02:17<1:17:33,  1.73it/s][A04/26/2020 16:26:32 - INFO - __main__ -   [BRAINQA] Loss: 3.244032859802246

Iteration:   2%|▏         | 197/8224 [02:18<1:21:11,  1.65it/s][A04/26/2020 16:26:32 - INFO - __main__ -   [BRAINQA] Loss: 2.158358097076416

Iteration:   2%|▏         | 198/8224 [02:19<1:23:32,  1.60it/s][A04/26/2020 16:26:33 - INFO - __main__ -   [BRAINQA] Loss: 2.7113757133483887
04/26/2020 16:26:33 - INFO - __main__ -   [BRAINQA] Eval loss: 2.594

Iteration:   2%|▏         | 199/8224 [02:19<1:24:13,  1.59it/s][A04/26/2020 16:26:34 - INFO - __main__ -   [BRAINQA] Loss: 2.465920925140381

Iteration:   2%|▏         | 200/8224 [02:20<1:24:07,  1.59it/s][A04/26/2020 16:26:34 - INFO - __main__ -   [BRAINQA] Loss: 2.6690163612365723

Iteration:   2%|▏         | 201/8224 [02:21<1:29:42,  1.49it/s][A04/26/2020 16:26:35 - INFO - __main__ -   [BRAINQA] Loss: 2.455679416656494

Iteration:   2%|▏         | 202/8224 [02:21<1:25:06,  1.57it/s][A04/26/2020 16:26:36 - INFO - __main__ -   [BRAINQA] Loss: 2.6698436737060547

Iteration:   2%|▏         | 203/8224 [02:22<1:25:26,  1.56it/s][A04/26/2020 16:26:36 - INFO - __main__ -   [BRAINQA] Loss: 2.2448995113372803

Iteration:   2%|▏         | 204/8224 [02:22<1:23:05,  1.61it/s][A04/26/2020 16:26:37 - INFO - __main__ -   [BRAINQA] Loss: 2.9747464656829834

Iteration:   2%|▏         | 205/8224 [02:23<1:16:50,  1.74it/s][A04/26/2020 16:26:37 - INFO - __main__ -   [BRAINQA] Loss: 2.110524892807007

Iteration:   3%|▎         | 206/8224 [02:23<1:12:05,  1.85it/s][A04/26/2020 16:26:38 - INFO - __main__ -   [BRAINQA] Loss: 2.0838029384613037

Iteration:   3%|▎         | 207/8224 [02:24<1:12:07,  1.85it/s][A04/26/2020 16:26:38 - INFO - __main__ -   [BRAINQA] Loss: 1.9535706043243408

Iteration:   3%|▎         | 208/8224 [02:24<1:11:56,  1.86it/s][A04/26/2020 16:26:39 - INFO - __main__ -   [BRAINQA] Loss: 2.26851224899292

Iteration:   3%|▎         | 209/8224 [02:25<1:15:39,  1.77it/s][A04/26/2020 16:26:39 - INFO - __main__ -   [BRAINQA] Loss: 2.152395248413086

Iteration:   3%|▎         | 210/8224 [02:26<1:18:55,  1.69it/s][A04/26/2020 16:26:40 - INFO - __main__ -   [BRAINQA] Loss: 2.0409154891967773

Iteration:   3%|▎         | 211/8224 [02:26<1:21:39,  1.64it/s][A04/26/2020 16:26:41 - INFO - __main__ -   [BRAINQA] Loss: 2.3747129440307617

Iteration:   3%|▎         | 212/8224 [02:27<1:23:54,  1.59it/s][A04/26/2020 16:26:41 - INFO - __main__ -   [BRAINQA] Loss: 1.3179924488067627

Iteration:   3%|▎         | 213/8224 [02:28<1:24:02,  1.59it/s][A04/26/2020 16:26:42 - INFO - __main__ -   [BRAINQA] Loss: 2.7287750244140625

Iteration:   3%|▎         | 214/8224 [02:28<1:23:54,  1.59it/s][A04/26/2020 16:26:43 - INFO - __main__ -   [BRAINQA] Loss: 3.211843490600586

Iteration:   3%|▎         | 215/8224 [02:29<1:27:22,  1.53it/s][A04/26/2020 16:26:43 - INFO - __main__ -   [BRAINQA] Loss: 2.2473137378692627

Iteration:   3%|▎         | 216/8224 [02:30<1:30:28,  1.48it/s][A04/26/2020 16:26:44 - INFO - __main__ -   [BRAINQA] Loss: 2.138723373413086

Iteration:   3%|▎         | 217/8224 [02:30<1:25:37,  1.56it/s][A04/26/2020 16:26:44 - INFO - __main__ -   [BRAINQA] Loss: 2.4726743698120117

Iteration:   3%|▎         | 218/8224 [02:31<1:18:55,  1.69it/s][A04/26/2020 16:26:45 - INFO - __main__ -   [BRAINQA] Loss: 2.0253305435180664

Iteration:   3%|▎         | 219/8224 [02:31<1:13:30,  1.81it/s][A04/26/2020 16:26:45 - INFO - __main__ -   [BRAINQA] Loss: 2.630898952484131

Iteration:   3%|▎         | 220/8224 [02:32<1:09:32,  1.92it/s][A04/26/2020 16:26:46 - INFO - __main__ -   [BRAINQA] Loss: 3.3374032974243164

Iteration:   3%|▎         | 221/8224 [02:32<1:09:54,  1.91it/s][A04/26/2020 16:26:47 - INFO - __main__ -   [BRAINQA] Loss: 3.0632309913635254

Iteration:   3%|▎         | 222/8224 [02:33<1:13:49,  1.81it/s][A04/26/2020 16:26:47 - INFO - __main__ -   [BRAINQA] Loss: 2.6798019409179688

Iteration:   3%|▎         | 223/8224 [02:33<1:17:21,  1.72it/s][A04/26/2020 16:26:48 - INFO - __main__ -   [BRAINQA] Loss: 1.9233529567718506

Iteration:   3%|▎         | 224/8224 [02:34<1:20:03,  1.67it/s][A04/26/2020 16:26:48 - INFO - __main__ -   [BRAINQA] Loss: 2.218026638031006

Iteration:   3%|▎         | 225/8224 [02:35<1:23:06,  1.60it/s][A04/26/2020 16:26:49 - INFO - __main__ -   [BRAINQA] Loss: 2.446687698364258

Iteration:   3%|▎         | 226/8224 [02:35<1:25:28,  1.56it/s][A04/26/2020 16:26:50 - INFO - __main__ -   [BRAINQA] Loss: 3.007997989654541

Iteration:   3%|▎         | 227/8224 [02:36<1:24:55,  1.57it/s][A04/26/2020 16:26:50 - INFO - __main__ -   [BRAINQA] Loss: 2.0922231674194336

Iteration:   3%|▎         | 228/8224 [02:37<1:25:02,  1.57it/s][A04/26/2020 16:26:51 - INFO - __main__ -   [BRAINQA] Loss: 1.7291064262390137

Iteration:   3%|▎         | 229/8224 [02:38<1:36:12,  1.39it/s][A04/26/2020 16:26:52 - INFO - __main__ -   [BRAINQA] Loss: 1.942312479019165

Iteration:   3%|▎         | 230/8224 [02:38<1:26:47,  1.54it/s][A04/26/2020 16:26:52 - INFO - __main__ -   [BRAINQA] Loss: 2.1436712741851807

Iteration:   3%|▎         | 231/8224 [02:39<1:19:45,  1.67it/s][A04/26/2020 16:26:53 - INFO - __main__ -   [BRAINQA] Loss: 2.31337308883667

Iteration:   3%|▎         | 232/8224 [02:39<1:14:20,  1.79it/s][A04/26/2020 16:26:53 - INFO - __main__ -   [BRAINQA] Loss: 2.369619369506836

Iteration:   3%|▎         | 233/8224 [02:40<1:09:55,  1.90it/s][A04/26/2020 16:26:54 - INFO - __main__ -   [BRAINQA] Loss: 2.3554635047912598

Iteration:   3%|▎         | 234/8224 [02:40<1:09:49,  1.91it/s][A04/26/2020 16:26:54 - INFO - __main__ -   [BRAINQA] Loss: 2.472446918487549

Iteration:   3%|▎         | 235/8224 [02:41<1:13:54,  1.80it/s][A04/26/2020 16:26:55 - INFO - __main__ -   [BRAINQA] Loss: 2.7826125621795654

Iteration:   3%|▎         | 236/8224 [02:41<1:17:32,  1.72it/s][A04/26/2020 16:26:56 - INFO - __main__ -   [BRAINQA] Loss: 2.204836130142212

Iteration:   3%|▎         | 237/8224 [02:42<1:20:11,  1.66it/s][A04/26/2020 16:26:56 - INFO - __main__ -   [BRAINQA] Loss: 2.5543904304504395

Iteration:   3%|▎         | 238/8224 [02:43<1:22:53,  1.61it/s][A04/26/2020 16:26:57 - INFO - __main__ -   [BRAINQA] Loss: 2.902609348297119

Iteration:   3%|▎         | 239/8224 [02:43<1:25:42,  1.55it/s][A